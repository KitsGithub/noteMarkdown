### 音视频入门

![](source/animation-1.gif)

- 视频原理

  - `YUV`图片：本质上就是图标一帧一帧播放的过程，与我们平时接触的 JPE、PNG的图片是一样的。但是为了效率原因，视频中解码出来的图片帧叫YUV
  - `PCM`音频：通常由`MP3`或者`AAC`等格式的音频二进制中，解码出来的音频采样点。可以理解为一片`PCM`音频等于一个声音单位
  - 音视频同步：在计算机渲染到图层的同时，根据DTS、PTS来同步播放音频帧（DTS、PTS后续介绍）

- I、P、B帧介绍

  在实际中，我们并不会吧每一帧完整的图片进行传输，因为这样会导致视频的体积很大，对数据的存储和网络传输来说都代价很大。因而，通常会对视频的部分画面进行压缩（编码）处理。根据压缩处理方式不同，画面帧就分为I 帧、P帧、B帧

  - I 帧：I 帧图像采用帧内编码方式，即只利用了单帧图像内的空间相关性，而没有利用时间相关性。I 帧使用帧内压缩，不使用运动补偿，由于 I 帧不依赖其它帧，所以是随机存取的入点，同时是解码的 `基准帧`。I 帧主要用于接收机的初始化和信道的获取，以及节目的切换和插入，I 帧图像的压缩倍数相对较低。I 帧图像是周期性出现在图像序列中的，出现频率可由编码器选择。
  - P帧：P 帧和 B 帧图像采用帧间编码方式，即同时利用了空间和时间上的相关性。P 帧图像只采用前向时间预测，可以提高压缩效率和图像质量。P 帧图像中可以包含帧内编码的部分，即 P 帧中的每一个宏块可以是前向预测，也可以是帧内编码。
  - B帧：B 帧图像采用双向时间预测，可以大大提高压缩倍数。值得注意的是，由于 B 帧图像采用了未来帧作为参考，因此 MPEG-2 编码码流中图像帧的传输顺序和显示顺序是不同的。

  也就是说，I 帧可以不依赖其他帧就可以解码出一个完整的图像，而P帧、B帧不行。P 帧需要依赖视频流中排在P帧前的帧才能解码出图像。而B帧则需要依赖视频流中排在它前面或者后面的帧才能解码出图像

  这里就会有一个问题，既然这样，在视频流中，先到的B帧无法立即解码，需要依赖它后面的I 、P帧先解码完成，这样一来播放时间和顺序就不一致了，顺序被打乱，那么该如何播放？这里引申出来2个东西： `DTS` 、 `PTS`

- DTS、PTS

  - DTS（Decoding Time Stamp）：即解码时间戳，这个时间戳的意义在于告诉播放器该在什么时候解码这一帧的数据。
  - PTS（Presentation Time Stamp）：即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据。

  现在来解释之前提到的问题：

  假设某一段视频流的显示顺序是 `I B B P`

  那个在视频流中的顺序可能是 `I P B B`

  DTS告诉我们应按什么顺序解码这几帧的视频。PTS告诉我们该按什么顺序显示这几帧视频

  顺序大概如下所示

  ```js
  	PTS: 1 4 2 3
  	DTS: 1 2 3 4
  Strem: I P B B
  --------------->
  ```

  

- 码率介绍

- 帧数介绍

- 轨道（音轨、画面）

- 编码格式。H.264

- AAC、MOV